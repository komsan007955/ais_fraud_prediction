{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "spark.conf.set(\"parquet.encryption.key.provider\", \"null\")\n",
        "spark.conf.set(\"parquet.encryption.column.keys\", \"\")\n",
        "spark.conf.set(\"parquet.encryption.footer.key\", \"\")\n",
        "\n",
        "aftm_store_path = \"/data/zeus/store/ais_fraud_prediction\"\n",
        "aftm_upload_path = \"/data/zeus/upload/ais_fraud_prediction\"\n",
        "\n",
        "aftm_time_ver = \"202312071741\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "aftm_df_orig = spark.read.parquet(f\"{aftm_store_path}/dataset/purchase_history\")\n",
        "aftm_df_prof = spark.read.parquet(f\"{aftm_store_path}/dataset/customer_profile\")\n",
        "\n",
        "aftm_df_orig.createOrReplaceTempView(\"purchase_history\")\n",
        "aftm_df_prof.createOrReplaceTempView(\"customer_profile\")\n",
        "\n",
        "aftm_df = spark.sql(\"select a2.*, a1.is_fraud from purchase_history as a1 left join customer_profile as a2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "aftm_num_samp_rows = 1000\n",
        "aftm_samp_fr = aftm_num_samp_rows / aftm_df.count()\n",
        "aftm_df_sample = aftm_df.sample(aftm_samp_fr)\n",
        "aftm_df_pd = aftm_df_sample.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "aftm_us_states = [\n",
        "    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
        "    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
        "    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
        "    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
        "    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n",
        "]\n",
        "\n",
        "def aftm_format_phone_no(phone_no):\n",
        "    phone_no_red = phone_no\n",
        "\n",
        "    if \"x\" in phone_no:\n",
        "        phone_no_red = phone_no.split(\"x\")[0]\n",
        "    if \"+\" in phone_no:\n",
        "        phone_no_red = \"\".join(phone_no_red.split(\"-\")[1:])\n",
        "\n",
        "    return phone_no_red \\\n",
        "        .replace(\"-\", \"\") \\\n",
        "        .replace(\".\", \"\") \\\n",
        "        .replace(\"(\", \"\") \\\n",
        "        .replace(\")\", \"\")\n",
        "\n",
        "aftm_df_pd_trf = aftm_df_pd.copy()\n",
        "aftm_df_pd_trf[\"mailing_platform\"] = aftm_df_pd_trf[\"email\"].apply(lambda x: x.split(\"@\")[1])\n",
        "aftm_df_pd_trf[\"state\"] = aftm_df_pd_trf[\"address\"].apply(lambda x: x.split(\" \")[-2])\n",
        "aftm_df_pd_trf[\"state_valid\"] = aftm_df_pd_trf[\"state\"].apply(lambda x: 1 if x in aftm_us_states else 0)\n",
        "aftm_df_pd_trf[\"state\"] = aftm_df_pd_trf[[\"state\", \"state_valid\"]].apply(lambda x: x[0] if x[1] else \"IV\", axis=1)\n",
        "aftm_df_pd_trf[\"contact_phone\"] = aftm_df_pd_trf[\"contact_phone\"].apply(lambda x: aftm_format_phone_no(x))\n",
        "aftm_df_pd_trf[\"contact_phone_valid\"] = aftm_df_pd_trf[\"contact_phone\"].apply(lambda x: 1 if len(x) == 10 else 0)\n",
        "aftm_df_pd_trf[\"credit_card_no_valid\"] = aftm_df_pd_trf[\"credit_card_no\"].apply(lambda x: 1 if len(x) == 10 else 0)\n",
        "aftm_df_pd_trf[\"birth_month\"] = aftm_df_pd_trf[\"date_of_birth\"].apply(lambda x: int(x.split(\"-\")[1]))\n",
        "aftm_df_pd_trf[\"birth_year\"] = aftm_df_pd_trf[\"date_of_birth\"].apply(lambda x: int(x.split(\"-\")[0]))\n",
        "aftm_df_pd_trf[\"membership_month\"] = aftm_df_pd_trf[\"member_since\"].apply(lambda x: int(x.split(\"-\")[1]))\n",
        "aftm_df_pd_trf[\"membership_year\"] = aftm_df_pd_trf[\"member_since\"].apply(lambda x: int(x.split(\"-\")[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "aftm_oe_inp_cols = [\"mailing_platform\", \"state\", \"sex\", \"status\"]\n",
        "aftm_ohe_inp_cols = [\"state_valid\", \"contact_phone_valid\", \"credit_card_no_valid\", \"birth_month\", \"membership_month\"]\n",
        "aftm_mms_inp_cols = [\"birth_year\", \"membership_year\"]\n",
        "\n",
        "aftm_pl = Pipeline(steps=[\n",
        "    (\"fu\", \n",
        "        FeatureUnion([\n",
        "            (\"pl\", \n",
        "                Pipeline(steps=[\n",
        "                    (\"ctoe\", ColumnTransformer(transformers=[(\"oe\", OrdinalEncoder(), aftm_oe_inp_cols)])),\n",
        "                    (\"ohe0\", OneHotEncoder(sparse=False))\n",
        "                ])\n",
        "            ),\n",
        "            (\"ctohe\", ColumnTransformer(transformers=[(\"ohe1\", OneHotEncoder(sparse=False), aftm_ohe_inp_cols)])),\n",
        "            (\"ctmms\", ColumnTransformer(transformers=[(\"mms\", MinMaxScaler(), aftm_mms_inp_cols)]))\n",
        "        ])\n",
        "    ),\n",
        "    (\"pca\", PCA()),\n",
        "    (\"rfc\", RandomForestClassifier())\n",
        "])\n",
        "\n",
        "aftm_pl_md = aftm_pl.fit(aftm_df_pd_trf, aftm_df_pd[\"is_fraud\"].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "import pickle\n",
        "\n",
        "pickle.dump(aftm_pl_md, open(f\"{aftm_store_path}/mvp1/model_{aftm_time_ver}.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "ais_fraud_train_ml_sklearn"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
