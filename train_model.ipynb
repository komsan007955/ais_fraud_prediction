{
  "metadata" : {
    "name" : "ais_fraud_train_ml_sklearn",
    "kernelspec" : {
      "language" : "scala",
      "name" : "spark2-scala"
    },
    "language_info" : {
      "codemirror_mode" : "text/x-scala",
      "file_extension" : ".scala",
      "mimetype" : "text/x-scala",
      "name" : "scala",
      "pygments_lexer" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 2,
  "cells" : [ {
    "cell_type" : "code",
    "execution_count" : 0,
    "metadata" : {
      "autoscroll" : "auto"
    },
    "outputs" : [ ],
    "source" : "%pyspark\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import *\n\nspark.conf.set(\"parquet.encryption.key.provider\", \"null\")\nspark.conf.set(\"parquet.encryption.column.keys\", \"\")\nspark.conf.set(\"parquet.encryption.footer.key\", \"\")\n\naftm_store_path = \"/data/zeus/store/ais_fraud_prediction\"\naftm_upload_path = \"/data/zeus/upload/ais_fraud_prediction\"\n\ntime_ver = \"202312071741\""
  }, {
    "cell_type" : "code",
    "execution_count" : 1,
    "metadata" : {
      "autoscroll" : "auto"
    },
    "outputs" : [ ],
    "source" : "%pyspark\naftm_df_orig = spark.read.parquet(f\"{aftm_store_path}/dataset/purchase_history\")\naftm_df_prof = spark.read.parquet(f\"{aftm_store_path}/dataset/customer_profile\")\n\naftm_df_orig.createOrReplaceTempView(\"purchase_history\")\naftm_df_prof.createOrReplaceTempView(\"customer_profile\")\n\naftm_df = spark.sql(\"select a2.*, a1.is_fraud from purchase_history as a1 left join customer_profile as a2\")"
  }, {
    "cell_type" : "code",
    "execution_count" : 2,
    "metadata" : {
      "autoscroll" : "auto"
    },
    "outputs" : [ ],
    "source" : "%pyspark\naftm_num_samp_rows = 1000\naftm_samp_fr = aftm_num_samp_rows / aftm_df.count()\naftm_df_sample = aftm_df.sample(aftm_samp_fr)\naftm_df_pd = aftm_df_sample.toPandas()"
  }, {
    "cell_type" : "code",
    "execution_count" : 3,
    "metadata" : {
      "autoscroll" : "auto"
    },
    "outputs" : [ ],
    "source" : "%pyspark\naftm_us_states = [\n    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"\n]\n\ndef aftm_format_phone_no(phone_no):\n    phone_no_red = phone_no\n\n    if \"x\" in phone_no:\n        phone_no_red = phone_no.split(\"x\")[0]\n    if \"+\" in phone_no:\n        phone_no_red = \"\".join(phone_no_red.split(\"-\")[1:])\n\n    return phone_no_red \\\n        .replace(\"-\", \"\") \\\n        .replace(\".\", \"\") \\\n        .replace(\"(\", \"\") \\\n        .replace(\")\", \"\")\n\naftm_df_pd_trf = aftm_df_pd.copy()\naftm_df_pd_trf[\"mailing_platform\"] = aftm_df_pd_trf[\"email\"].apply(lambda x: x.split(\"@\")[1])\naftm_df_pd_trf[\"state\"] = aftm_df_pd_trf[\"address\"].apply(lambda x: x.split(\" \")[-2])\naftm_df_pd_trf[\"state_valid\"] = aftm_df_pd_trf[\"state\"].apply(lambda x: 1 if x in aftm_us_states else 0)\naftm_df_pd_trf[\"state\"] = aftm_df_pd_trf[[\"state\", \"state_valid\"]].apply(lambda x: x[0] if x[1] else \"IV\", axis=1)\naftm_df_pd_trf[\"contact_phone\"] = aftm_df_pd_trf[\"contact_phone\"].apply(lambda x: aftm_format_phone_no(x))\naftm_df_pd_trf[\"contact_phone_valid\"] = aftm_df_pd_trf[\"contact_phone\"].apply(lambda x: 1 if len(x) == 10 else 0)\naftm_df_pd_trf[\"credit_card_no_valid\"] = aftm_df_pd_trf[\"credit_card_no\"].apply(lambda x: 1 if len(x) == 10 else 0)\naftm_df_pd_trf[\"birth_month\"] = aftm_df_pd_trf[\"date_of_birth\"].apply(lambda x: int(x.split(\"-\")[1]))\naftm_df_pd_trf[\"birth_year\"] = aftm_df_pd_trf[\"date_of_birth\"].apply(lambda x: int(x.split(\"-\")[0]))\naftm_df_pd_trf[\"membership_month\"] = aftm_df_pd_trf[\"member_since\"].apply(lambda x: int(x.split(\"-\")[1]))\naftm_df_pd_trf[\"membership_year\"] = aftm_df_pd_trf[\"member_since\"].apply(lambda x: int(x.split(\"-\")[0]))"
  }, {
    "cell_type" : "code",
    "execution_count" : 4,
    "metadata" : {
      "autoscroll" : "auto"
    },
    "outputs" : [ ],
    "source" : "%pyspark\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\n\naftm_oe_inp_cols = [\"mailing_platform\", \"state\", \"sex\", \"status\"]\naftm_ohe_inp_cols = [\"state_valid\", \"contact_phone_valid\", \"credit_card_no_valid\", \"birth_month\", \"membership_month\"]\naftm_mms_inp_cols = [\"birth_year\", \"membership_year\"]\n\naftm_pl = Pipeline(steps=[\n    (\"fu\", \n        FeatureUnion([\n            (\"pl\", \n                Pipeline(steps=[\n                    (\"ctoe\", ColumnTransformer(transformers=[(\"oe\", OrdinalEncoder(), aftm_oe_inp_cols)])),\n                    (\"ohe0\", OneHotEncoder(sparse=False))\n                ])\n            ),\n            (\"ctohe\", ColumnTransformer(transformers=[(\"ohe1\", OneHotEncoder(sparse=False), aftm_ohe_inp_cols)])),\n            (\"ctmms\", ColumnTransformer(transformers=[(\"mms\", MinMaxScaler(), aftm_mms_inp_cols)]))\n        ])\n    ),\n    (\"pca\", PCA()),\n    (\"rfc\", RandomForestClassifier())\n])\n\naftm_pl_md = aftm_pl.fit(aftm_df_pd_trf, aftm_df_pd[\"is_fraud\"].values)"
  }, {
    "cell_type" : "code",
    "execution_count" : 5,
    "metadata" : {
      "autoscroll" : "auto"
    },
    "outputs" : [ ],
    "source" : "%pyspark\nimport pickle\n\npickle.dump(aftm_pl_md, open(f\"{aftm_store_path}/mvp1/model_{time_ver}.pkl\", \"wb\"))"
  }, {
    "cell_type" : "code",
    "execution_count" : 6,
    "metadata" : {
      "autoscroll" : "auto"
    },
    "outputs" : [ ],
    "source" : "%pyspark"
  } ]
}