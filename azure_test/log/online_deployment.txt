Instance status:
SystemSetup: Succeeded
UserContainerImagePull: Succeeded
ModelDownload: Succeeded
UserContainerStart: InProgress

Container events:
Kind: Pod, Name: Downloading, Type: Normal, Time: 2023-11-17T08:17:14.24196Z, Message: Start downloading models
Kind: Pod, Name: Pulling, Type: Normal, Time: 2023-11-17T08:17:18.836322Z, Message: Start pulling container image
Kind: Pod, Name: Pulled, Type: Normal, Time: 2023-11-17T08:18:29.28428Z, Message: Container image is pulled successfully
Kind: Pod, Name: Downloaded, Type: Normal, Time: 2023-11-17T08:18:29.28428Z, Message: Models are downloaded successfully
Kind: Pod, Name: Created, Type: Normal, Time: 2023-11-17T08:18:29.331451Z, Message: Created container inference-server
Kind: Pod, Name: Started, Type: Normal, Time: 2023-11-17T08:18:29.39775Z, Message: Started container inference-server

Container logs:
/bin/bash: /azureml-envs/sklearn-1.1/lib/libtinfo.so.6: no version information available (required by /bin/bash)
/bin/bash: /azureml-envs/sklearn-1.1/lib/libtinfo.so.6: no version information available (required by /bin/bash)
/bin/bash: /azureml-envs/sklearn-1.1/lib/libtinfo.so.6: no version information available (required by /bin/bash)
2023-11-17T08:18:29,399720774+00:00 - rsyslog/run 
bash: /azureml-envs/sklearn-1.1/lib/libtinfo.so.6: no version information available (required by bash)
2023-11-17T08:18:29,407686369+00:00 - gunicorn/run 
2023-11-17T08:18:29,410017455+00:00 | gunicorn/run | 
2023-11-17T08:18:29,411873224+00:00 | gunicorn/run | ###############################################
2023-11-17T08:18:29,413267575+00:00 | gunicorn/run | AzureML Container Runtime Information
2023-11-17T08:18:29,414561423+00:00 | gunicorn/run | ###############################################
2023-11-17T08:18:29,415940874+00:00 | gunicorn/run | 
2023-11-17T08:18:29,415998876+00:00 - nginx/run 
2023-11-17T08:18:30,035907514+00:00 | gunicorn/run | 
2023-11-17T08:18:30,038518410+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20231030.v1
2023-11-17T08:18:30,039958863+00:00 | gunicorn/run | 
2023-11-17T08:18:30,041308713+00:00 | gunicorn/run | 
2023-11-17T08:18:30,042640162+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/sklearn-1.1/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2023-11-17T08:18:30,044124217+00:00 | gunicorn/run | PYTHONPATH environment variable: 
2023-11-17T08:18:30,045510768+00:00 | gunicorn/run | 
2023-11-17T08:18:30,308120056+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda

# conda environments:
#
                      *  /azureml-envs/sklearn-1.1
base                     /opt/miniconda

2023-11-17T08:18:30,891972295+00:00 | gunicorn/run | 
2023-11-17T08:18:30,897611803+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)

absl-py==2.0.0
adal==1.2.7
applicationinsights==0.11.10
argcomplete==2.1.2
asttokens==2.4.1
attrs==23.1.0
azure-common==1.1.28
azure-core==1.29.5
azure-graphrbac==0.61.1
azure-identity==1.15.0
azure-mgmt-authorization==3.0.0
azure-mgmt-containerregistry==10.2.0
azure-mgmt-core==1.4.0
azure-mgmt-keyvault==10.3.0
azure-mgmt-network==21.0.1
azure-mgmt-resource==22.0.0
azure-mgmt-storage==21.0.0
azure-storage-blob==12.13.0
azureml-automl-common-tools==1.53.0
azureml-core==1.53.0
azureml-dataprep==4.12.6
azureml-dataprep-native==38.0.0
azureml-dataprep-rslex==2.19.6
azureml-dataset-runtime==1.53.0
azureml-defaults==1.53.0
azureml-inference-server-http==0.8.4.2
azureml-mlflow==1.53.0
azureml-telemetry==1.53.0
backcall==0.2.0
backports.tempfile==1.0
backports.weakref==1.0.post1
bcrypt==4.0.1
Bottleneck @ file:///opt/conda/conda-bld/bottleneck_1657175564434/work
Brotli @ file:///tmp/abs_ecyw11_7ze/croots/recipe/brotli-split_1659616059936/work
cachetools==5.3.2
certifi @ file:///croot/certifi_1690232220950/work/certifi
cffi @ file:///croot/cffi_1670423208954/work
charset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work
click==8.1.7
cloudpickle==2.2.1
comm==0.2.0
contextlib2==21.6.0
cryptography==41.0.5
cycler==0.12.1
daal==2023.2.1
daal4py==2023.2.1
databricks-cli==0.18.0
debugpy==1.6.7.post1
decorator==5.1.1
distro==1.8.0
docker==6.1.3
dotnetcore2==3.1.23
entrypoints==0.4
executing==2.0.1
Flask==2.2.5
Flask-Cors==3.0.10
fonttools==4.44.0
fusepy==3.0.1
gitdb==4.0.11
GitPython==3.1.40
google-api-core==2.12.0
google-auth==2.23.4
google-auth-oauthlib==1.0.0
googleapis-common-protos==1.61.0
grpcio==1.59.2
gunicorn==20.1.0
humanfriendly==10.0
idna @ file:///croot/idna_1666125576474/work
importlib-metadata==6.8.0
importlib-resources==6.1.0
inference-schema==1.7
ipykernel==6.26.0
ipython==8.12.3
isodate==0.6.1
itsdangerous==2.1.2
jedi==0.19.1
jeepney==0.8.0
Jinja2==3.1.2
jmespath==1.0.1
joblib==1.2.0
jsonpickle==3.0.2
jsonschema==4.19.2
jsonschema-specifications==2023.7.1
jupyter_client==8.6.0
jupyter_core==5.5.0
kiwisolver==1.4.5
knack==0.10.1
Markdown==3.5.1
MarkupSafe==2.1.3
matplotlib==3.5.3
matplotlib-inline==0.1.6
mkl-fft @ file:///croot/mkl_fft_1695058164594/work
mkl-random @ file:///croot/mkl_random_1695059800811/work
mkl-service==2.4.0
mlflow-skinny==2.8.0
msal==1.25.0
msal-extensions==1.0.0
msrest==0.7.1
msrestazure==0.6.4
ndg-httpsclient==0.5.1
nest-asyncio==1.5.8
numexpr @ file:///croot/numexpr_1683221822650/work
numpy @ file:///work/mkl/numpy_and_numpy_base_1682952083030/work
oauthlib==3.2.2
opencensus==0.11.3
opencensus-context==0.1.3
opencensus-ext-azure==1.1.11
packaging==23.0
pandas==1.3.5
paramiko==3.3.1
parso==0.8.3
pathspec==0.11.2
pexpect==4.8.0
pickleshare==0.7.5
Pillow==10.1.0
pkginfo==1.9.6
pkgutil_resolve_name==1.3.10
platformdirs @ file:///croot/platformdirs_1692205439124/work
pooch @ file:///croot/pooch_1695850093751/work
portalocker==2.8.2
prompt-toolkit==3.0.39
protobuf==4.25.0
psutil==5.8.0
ptyprocess==0.7.0
pure-eval==0.2.2
py-cpuinfo==5.0.0
py-spy==0.3.12
pyarrow==11.0.0
pyasn1==0.5.0
pyasn1-modules==0.3.0
pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work
pydantic==1.10.13
Pygments==2.16.1
PyJWT==2.8.0
PyNaCl==1.5.0
pyOpenSSL @ file:///croot/pyopenssl_1690223430423/work
pyparsing==3.1.1
PySocks @ file:///tmp/build/80754af9/pysocks_1605305779399/work
python-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work
pytz @ file:///croot/pytz_1695131579487/work
PyYAML==6.0.1
pyzmq==25.1.1
referencing==0.30.2
requests @ file:///croot/requests_1690400202158/work
requests-oauthlib==1.3.1
rpds-py==0.12.0
rsa==4.9
scikit-learn==1.1.3
scikit-learn-intelex==2023.2.1
scipy==1.10.1
SecretStorage==3.3.3
six @ file:///tmp/build/80754af9/six_1644875935023/work
smmap==5.0.1
sqlparse==0.4.4
stack-data==0.6.3
tabulate==0.9.0
tbb==2021.10.0
tensorboard==2.14.0
tensorboard-data-server==0.7.2
threadpoolctl==3.2.0
torch-tb-profiler==0.4.3
tornado==6.3.3
tqdm==4.62.3
traitlets==5.13.0
typing_extensions==4.8.0
urllib3 @ file:///croot/urllib3_1698257533958/work
wcwidth==0.2.9
websocket-client==1.6.4
Werkzeug==3.0.1
wrapt==1.12.1
zipp==3.17.0

2023-11-17T08:18:31,398379578+00:00 | gunicorn/run | 
2023-11-17T08:18:31,399860132+00:00 | gunicorn/run | Entry script directory: /var/azureml-app/231117151323-4046234838/.
2023-11-17T08:18:31,401407889+00:00 | gunicorn/run | 
2023-11-17T08:18:31,403062250+00:00 | gunicorn/run | ###############################################
2023-11-17T08:18:31,404713911+00:00 | gunicorn/run | Dynamic Python Package Installation
2023-11-17T08:18:31,407252405+00:00 | gunicorn/run | ###############################################
2023-11-17T08:18:31,409139675+00:00 | gunicorn/run | 
2023-11-17T08:18:31,410958842+00:00 | gunicorn/run | Dynamic Python package installation is disabled.
2023-11-17T08:18:31,412376994+00:00 | gunicorn/run | 
2023-11-17T08:18:31,413713143+00:00 | gunicorn/run | ###############################################
2023-11-17T08:18:31,415145896+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed
2023-11-17T08:18:31,416524147+00:00 | gunicorn/run | ###############################################
2023-11-17T08:18:31,417936999+00:00 | gunicorn/run | 
2023-11-17T08:18:32,355569890+00:00 | gunicorn/run | 
2023-11-17T08:18:32,357197650+00:00 | gunicorn/run | ###############################################
2023-11-17T08:18:32,358496798+00:00 | gunicorn/run | AzureML Inference Server
2023-11-17T08:18:32,359870749+00:00 | gunicorn/run | ###############################################
2023-11-17T08:18:32,361174397+00:00 | gunicorn/run | 
2023-11-17T08:18:32,362813057+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.
2023-11-17 08:18:32,500 I [12] azmlinfsrv - Loaded logging config from /azureml-envs/sklearn-1.1/lib/python3.8/site-packages/azureml_inference_server_http/logging.json
2023-11-17 08:18:32,574 I [12] gunicorn.error - Starting gunicorn 20.1.0
2023-11-17 08:18:32,575 I [12] gunicorn.error - Listening at: http://0.0.0.0:31311 (12)
2023-11-17 08:18:32,575 I [12] gunicorn.error - Using worker: sync
2023-11-17 08:18:32,576 I [78] gunicorn.error - Booting worker with pid: 78

Azure ML Inferencing HTTP server v0.8.4.2


Server Settings
---------------
Entry Script Name: /var/azureml-app/231117151323-4046234838/scoring_script.py
Model Directory: /var/azureml-app/azureml-models/test/1
Config File: None
Worker Count: 1
Worker Timeout (seconds): 300
Server Port: 31311
Health Port: 31311
Application Insights Enabled: false
Application Insights Key: None
Inferencing HTTP server version: azmlinfsrv/0.8.4.2
CORS for the specified origins: None
Create dedicated endpoint for health: None


Server Routes
---------------
Liveness Probe: GET   127.0.0.1:31311/
Score:          POST  127.0.0.1:31311/score

2023-11-17 08:18:32,822 I [78] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.
Initializing logger
2023-11-17 08:18:32,824 I [78] azmlinfsrv - Starting up app insights client
2023-11-17 08:18:33,383 I [78] azmlinfsrv.user_script - Found user script at /var/azureml-app/231117151323-4046234838/scoring_script.py
2023-11-17 08:18:33,383 I [78] azmlinfsrv.user_script - run() is not decorated. Server will invoke it with the input in JSON string.
2023-11-17 08:18:33,383 I [78] azmlinfsrv.user_script - Invoking user's init function
ERROR:azureml.core.model:Model test not found in cache at /var/azureml-app/231117151323-4046234838/azureml-models or in current working directory /var/azureml-app/231117151323-4046234838. For more info, set logging level to DEBUG.

2023-11-17 08:18:33,383 E [78] azmlinfsrv - User's init function failed
2023-11-17 08:18:33,384 E [78] azmlinfsrv - Encountered Exception Traceback (most recent call last):
  File "/azureml-envs/sklearn-1.1/lib/python3.8/site-packages/azureml/core/model.py", line 796, in get_model_path
    return Model._get_model_path_local(model_name, version)
  File "/azureml-envs/sklearn-1.1/lib/python3.8/site-packages/azureml/core/model.py", line 828, in _get_model_path_local
    return Model._get_model_path_local_from_root(model_name)
  File "/azureml-envs/sklearn-1.1/lib/python3.8/site-packages/azureml/core/model.py", line 870, in _get_model_path_local_from_root
    raise ModelNotFoundException("Model {} not found in cache at {} or in current working directory {}. "
azureml.exceptions._azureml_exception.ModelNotFoundException: ModelNotFoundException:
	Message: Model test not found in cache at /var/azureml-app/231117151323-4046234838/azureml-models or in current working directory /var/azureml-app/231117151323-4046234838. For more info, set logging level to DEBUG.
	InnerException None
	ErrorResponse 
{
    "error": {
        "message": "Model test not found in cache at /var/azureml-app/231117151323-4046234838/azureml-models or in current working directory /var/azureml-app/231117151323-4046234838. For more info, set logging level to DEBUG."
    }
}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/azureml-envs/sklearn-1.1/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 119, in invoke_init
    self._user_init()
  File "/var/azureml-app/231117151323-4046234838/scoring_script.py", line 11, in init
    model_path = Model.get_model_path(model_name="test", version=1)
  File "/azureml-envs/sklearn-1.1/lib/python3.8/site-packages/azureml/core/model.py", line 802, in get_model_path
    raise WebserviceException(ee.message, logger=module_logger)
azureml.exceptions._azureml_exception.WebserviceException: WebserviceException:
	Message: Model test not found in cache at /var/azureml-app/231117151323-4046234838/azureml-models or in current working directory /var/azureml-app/231117151323-4046234838. For more info, set logging level to DEBUG.
	InnerException None
	ErrorResponse 
{
    "error": {
        "message": "Model test not found in cache at /var/azureml-app/231117151323-4046234838/azureml-models or in current working directory /var/azureml-app/231117151323-4046234838. For more info, set logging level to DEBUG."
    }
}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/azureml-envs/sklearn-1.1/lib/python3.8/site-packages/azureml_inference_server_http/server/aml_blueprint.py", line 109, in setup
    self.user_script.invoke_init()
  File "/azureml-envs/sklearn-1.1/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 121, in invoke_init
    raise UserScriptException(ex) from ex
azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script

2023-11-17 08:18:33,384 I [78] azmlinfsrv - Model Directory Contents:
2023-11-17 08:18:33,384 I [78] azmlinfsrv - 1/
2023-11-17 08:18:33,384 I [78] azmlinfsrv -     model.pkl
2023-11-17 08:18:33,385 I [78] gunicorn.error - Worker exiting (pid: 78)

Azure ML Inferencing HTTP server v0.8.4.2


Server Settings
---------------
Entry Script Name: /var/azureml-app/231117151323-4046234838/scoring_script.py
Model Directory: /var/azureml-app/azureml-models/test/1
Config File: None
Worker Count: 1
Worker Timeout (seconds): 300
Server Port: 31311
Health Port: 31311
Application Insights Enabled: false
Application Insights Key: None
Inferencing HTTP server version: azmlinfsrv/0.8.4.2
CORS for the specified origins: None
Create dedicated endpoint for health: None


Server Routes
---------------
Liveness Probe: GET   127.0.0.1:31311/
Score:          POST  127.0.0.1:31311/score

2023-11-17 08:18:33,572 I [12] gunicorn.error - Shutting down: Master
2023-11-17 08:18:33,573 I [12] gunicorn.error - Reason: Worker failed to boot.
/bin/bash: /azureml-envs/sklearn-1.1/lib/libtinfo.so.6: no version information available (required by /bin/bash)
2023-11-17T08:18:33,609249840+00:00 - gunicorn/finish 3 0
2023-11-17T08:18:33,610427084+00:00 - Exit code 3 is not normal. Killing image.

